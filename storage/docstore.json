{
    "RNN": "Definition: Recurrent Neural Networks (RNNs) are a class of artificial neural networks designed for sequential data processing. Unlike traditional feedforward networks, RNNs have connections that allow information to persist across time steps, making them well-suited for tasks involving sequences, such as time series analysis and natural language processing. Key Concepts for RNNs: Recurrent Connections: Unlike feedforward networks, RNNs have connections that loop back, allowing information to be passed from one time step to the next. This makes them effective for sequential data processing. Hidden States: The hidden state in an RNN serves as a memory that captures information about previous inputs, influencing future predictions. Activation Functions: Common activation functions in RNNs include tanh and ReLU, which introduce non-linearity and help the network learn complex patterns. Vanishing and Exploding Gradients: Due to long-term dependencies, RNNs may suffer from vanishing or exploding gradient problems, making it difficult to learn relationships over long sequences. Backpropagation Through Time (BPTT): BPTT is a variation of backpropagation used to train RNNs by unrolling the network over time and computing gradients. Applications: Speech recognition Machine translation Text generation Time series forecasting Music composition Sentiment analysis",
  
    "LSTM": "Definition: Long Short-Term Memory (LSTM) networks are a specialized type of Recurrent Neural Networks (RNNs) designed to overcome the vanishing gradient problem. LSTMs introduce memory cells and gating mechanisms, allowing them to learn long-term dependencies more effectively than standard RNNs. Key Concepts for LSTMs: Memory Cells: LSTMs contain memory cells that store information over long time periods, enabling effective handling of long sequences. Forget Gate: The forget gate determines what information should be discarded from the memory cell. It uses a sigmoid function to produce values between 0 and 1. Input Gate: The input gate controls what new information is added to the memory cell, determining how much new input should be stored. Output Gate: The output gate decides what information from the memory cell should be passed to the next hidden state. Cell State: The cell state is a key component of LSTMs that allows information to flow across multiple time steps with minimal modification, helping to retain long-term dependencies. Applications: Speech recognition Handwriting recognition Language modeling Video analysis Financial forecasting Healthcare analytics" ,
    
    "CNN": "Definition: Convolutional Neural Networks (CNNs or ConvNets) are a class of deep neural networks designed for processing and analyzing visual data, making them especially effective for tasks such as image recognition and computer vision. CNNs are characterized by their unique architecture, which includes convolutional layers, pooling layers, and fully connected layers. Key Concepts for CNNs: Convolutional Layers: Convolutional layers apply filters (also known as kernels) to input data, enabling the network to learn hierarchical features such as edges, textures, and patterns. Pooling Layers: Pooling layers downsample the spatial dimensions of the input data, reducing computational complexity and retaining important features. Common pooling operations include max pooling and average pooling. Activation Functions: Activation functions, such as ReLU (Rectified Linear Unit), introduce non-linearity to the network, allowing it to learn complex relationships and patterns. Fully Connected Layers: Fully connected layers connect every neuron from one layer to every neuron in the next layer, consolidating learned features for classification or regression tasks. Convolutional Filters: Filters capture local patterns in the input data, effectively learning features like edges, corners, and textures. These filters are adapted during training to recognize higher-level features. Striding: Striding controls the step size of the filter as it moves across the input data, influencing the spatial dimensions of the output. Striding helps reduce the spatial dimensions and computational load. Weight Sharing: CNNs leverage weight sharing, where the same set of parameters (weights and biases) is used across different regions of the input, facilitating the detection of similar features in different parts of an image. Padding: Padding involves adding extra pixels to the input data, preventing information loss at the borders during convolution. It ensures that the spatial dimensions of the input and output match appropriately. Dropout: Dropout is a regularization technique used to prevent overfitting by randomly setting a fraction of input units to zero during training, reducing reliance on specific neurons. Applications: Image classification, Object detection, Facial recognition, Image segmentation, Medical image analysis, Autonomous vehicles, Natural language processing (when combined with recurrent networks).",
  
    "Digital Camera": "Definition: A digital camera in computer vision refers to an electronic imaging device that captures visual information in the form of digital images. It plays a fundamental role in computer vision applications by providing a means to acquire, process, and analyze visual data for various tasks such as image recognition, object detection, and scene understanding. Key Concepts: Image Sensor: The image sensor converts light into electrical signals, forming the basis for digital image creation. Common types include CMOS (Complementary Metal-Oxide-Semiconductor) and CCD (Charge-Coupled Device) sensors. Resolution: The resolution of a digital camera is the number of pixels it can capture. Higher resolution contributes to finer details in images. Lens System: The lens system focuses light onto the image sensor. The choice of lenses influences factors like focal length, aperture, and depth of field. Colour Representation: Digital cameras capture color information using RGB (Red, Green, Blue) channels. Color representation is crucial for various computer vision tasks. Shutter Speed & Exposure: Shutter speed and exposure settings determine how long the camera's shutter remains open. They impact the amount of light reaching the sensor and influence image quality. White Balance: White balance adjustments ensure accurate color reproduction under different lighting conditions. Image Processing: In-built image processing capabilities enhance images and may include features like noise reduction, sharpness adjustment, and color correction. Frame Rate: The frame rate indicates how many images per second the camera can capture. It is crucial for applications like video analysis. Auto Focus: Autofocus systems and focus modes contribute to capturing sharp and clear images by adjusting the focus based on the scene."
  }
  